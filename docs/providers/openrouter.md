---
summary: "Use OpenRouter's unified API to access many models in AeonSage"
read_when:
  - You want a single API key for many LLMs
  - You want to run models via OpenRouter in AeonSage
---
# OpenRouter

OpenRouter provides a **unified API** that routes requests to many models behind a single
endpoint and API key. It is OpenAI-compatible, so most OpenAI SDKs work by switching the base URL.

## CLI setup

```bash
aeonsage onboard --auth-choice apiKey --token-provider openrouter --token "$OPENROUTER_API_KEY"
```

Get a key: https://openrouter.ai/keys

## Config snippet

```json5
{
  env: { OPENROUTER_API_KEY: "sk-or-..." },
  agents: {
    defaults: {
      model: { primary: "openrouter/auto" }
    }
  }
}
```

## Notes

- Model refs are `openrouter/<provider>/<model>`.
- `openrouter/auto` is the recommended default and auto-routes to the best model for each request.
- For more model/provider options, see [/concepts/model-providers](/concepts/model-providers).
- OpenRouter uses a Bearer token with your API key under the hood.

